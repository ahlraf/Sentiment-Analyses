#written in python, july 24 - aug 30

"""IMPORT MODULES"""

import pandas as pd 
import numpy as np 

import matplotlib.pyplot as plt 
import re
import string

import nltk
from nltk.tokenize import sent_tokenize
from nltk.corpus import words
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.sentiment.util import *
nltk.download('stopwords')
nltk.download('vader_lexicon')


from collections import Counter

from matplotlib import pyplot as plt
from matplotlib import ticker
import seaborn as sns
import plotly.express as px

sns.set(style="darkgrid")

#import dataset
df = pd.read_csv('https://raw.githubusercontent.com/gabrielpreda/covid-19-tweets/master/covid19_tweets.csv')

#df.shape

#keep required columns
needed_columns = ['user_name','date','text']
df = df[needed_columns]
#df.head()

#change type - assign number to name
df.user_name = df.user_name.astype('category')
df.user_name = df.user_type.cat.codes

#convert data to datetime
df.date = pd.to_datatime(df.date).dt.date

#take out tweet texts
texts = df['text']

#remove urls from tweets
remove_url = lambda x: re.sub('https\S+','',str(x))
texts_lr = texts.apply(remove_url)

#convert to lowercase
to_lower = lambda x: x.lower()
texts_lr_lc = texts_lr.apply(to_lower)

#remove punctuation
remove_punctuation = lambda x: x.translate(str.maketrans('','',string.punctuation))
texts_lr_lc_np = texts_lr_lc.apply(remove_punctuation)

#remove stopwords
more_words=['covid','#coronavirus', '#coronavirusoutbreak', '#coronavirusPandemic', '#covid19', '#covid_19', '#epitwitter', '#ihavecorona', 'amp', 'coronavirus', 'covid19']
stop_words = set(stopwords.words('English'))
stop_words.update(more_words)

remove_words = lambda x:' '.join([word for word in x.split() if word not in stop_words])
texts_lr_lc_np_ns = texts_lr_lc_np.apply(remove_words)
texts_lr_lc_np_ns

#create list of words 
words_list = [word for line in texts_lr_lc_np_ns for word in line.split()]

word_counts = Counter(words_list).most_common(50)
words_df = pd.DataFrame(word_counts)
words_df.columns = ['word','frq']
words_df.head()

px.bar(words_df,x='word',y='frq',title='most common words')

#cleaned up text in main dataframe
df.text = texts_lr_lc_np_ns

#polarity scores for each tweet
sid = SentimentIntensityAnalyzer()
ps = lambda x: sid.polarity_scores(x)
sentiment_scores = df.text.apply(ps)

sentiment_df = pd.DataFrame(data = list(sentiment_scores))
sentiment_df.head()

#label scores based on compound polarity values
labelize = lambda x: 'neutral' if x== 0 else('positive' if x>0 else 'negative')
sentiment_df['label'] = sentiment_df.compound.apply(labelize)

#join two dataframes 
data = df.join(sentiment_df.label)

#plot sentiment score counts
counts_df = data.label.value_counts().reset_index()

sns.barplot(x='index',y='label',data = counts_df)

#aggregation
data_agg = data[['user_name','date','label']].groupby(['date','label']).count().reset_index()

data_agg.columns = ['data','label','counts']

px.line(data_agg,x='date',y='counts',color='label',title='daily tweets sentiment analysis')




